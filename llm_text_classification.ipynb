{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d7c8d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install python-dotenv\n",
    "#%pip install openai\n",
    "#%pip install langchain langchain_openai\n",
    "#%pip install langchain-deepseek"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca2cef3",
   "metadata": {},
   "source": [
    "### load ENV VARIABLE API KEY AND INSTANTIATE A CLIENT FOR THIS API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76138e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not using colab\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "COLAB = False\n",
    "try:\n",
    "    from google.colab import drive, userdata\n",
    "    COLAB = True\n",
    "    print(\"using colab\")\n",
    "except:\n",
    "    print(\"not using colab\")\n",
    "#The deepseek-chat model points to DeepSeek-V3-0324 deepseek-chat\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "if COLAB:\n",
    "    os.environ[\"DEEPSEEK_API_KEY\"] = userdata.get('DEEPSEEK_API_KEY') #or OPENAI_API_KEY\n",
    "else:\n",
    "    #OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "    DEEPSEEK_API_KEY = os.getenv('DEEPSEEK_API_KEY')\n",
    "\n",
    "client = OpenAI(api_key=DEEPSEEK_API_KEY, base_url=\"https://api.deepseek.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb49223",
   "metadata": {},
   "source": [
    "### scrap some email corpus genAI from Jeff Heaton: https://www.youtube.com/watch?v=2VpOwFIGmA8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1063dc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_email(i):\n",
    "    if i<1 or i>10:\n",
    "        raise Exception(\"invalid email number\")\n",
    "    \n",
    "    url = f\"https://data.heatonresearch.com/wustl/CABI/genai-langchain/emails/email_{i}.txt\"\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        corpus = response.text\n",
    "        return corpus\n",
    "    else:\n",
    "        raise Exception(\"failed to retrieve the content\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eac5953b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dear Professor,\n",
      "\n",
      "I hope this message finds you well. I am currently working on Homework Assignment 7 and I'm finding some of the concepts challenging to grasp. Specifically, I'm struggling with the section on statistical analysis techniques. I've reviewed the lecture notes and the recommended textbook chapters, but I still have a few questions.\n",
      "\n",
      "Could we possibly arrange a time to meet during your office hours this week? I believe a brief discussion would really help clarify my doubts. Thank you very much for your time and assistance.\n",
      "\n",
      "Best regards,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(get_email(2)) #genAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6f995c",
   "metadata": {},
   "source": [
    "### read these emails and classify them:\n",
    "categories: spam, faculty (faculty announcements and requests), help (students requesting help on an assignment), lor (requesting letter of recommendation). If the email does not fit into these categories, say \"other\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98a6e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\josen\\anaconda3\\envs\\tadsml\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3517: UserWarning: WARNING! stream is not default parameter.\n",
      "                stream was transferred to model_kwargs.\n",
      "                Please confirm that stream is what you intended.\n",
      "  if await self.run_code(code, result, async_=asy):\n",
      "c:\\Users\\josen\\anaconda3\\envs\\tadsml\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3517: UserWarning: WARNING! response_format is not default parameter.\n",
      "                response_format was transferred to model_kwargs.\n",
      "                Please confirm that response_format is what you intended.\n",
      "  if await self.run_code(code, result, async_=asy):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Email #1 is: lor\n",
      "Email #2 is a question about assignment #7\n"
     ]
    }
   ],
   "source": [
    "from langchain_deepseek import ChatDeepSeek\n",
    "\n",
    "MODEL = \"deepseek-chat\"\n",
    "TEMPERATURE = 0.0\n",
    "MAX_TOKENS = 1024\n",
    "\n",
    "llm = ChatDeepSeek(\n",
    "    model=MODEL,\n",
    "    temperature=TEMPERATURE,\n",
    "    max_tokens=MAX_TOKENS,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    #stream=False,\n",
    "    response_format={'type': 'text'} #json_object\n",
    ")\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "from langchain_core.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    SystemMessagePromptTemplate\n",
    ")\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain, SimpleSequentialChain\n",
    "\n",
    "email_context = \"\"\"Classifiy the following email as either: \n",
    "          * spam - for marketing emails trying to sell something\n",
    "          * faculty - for faculty announcements and requests\n",
    "          * help - for students requesting help on an assignment\n",
    "          * lor - for students requesting letters of recommendation\n",
    "          * other - if it does not fit into any of these\n",
    "          Here is the email. Return code, such as spam. Return nothing else, do not explain your choice.\n",
    "          Make sure that if the email does not fit into one of these categories that you classify it as other.\n",
    "          Here it is the email:\n",
    "          {email}\"\"\"\n",
    "\n",
    "help_context = \"\"\"You are given an email where student is asking about an assignment. Return the assignment number that they are\n",
    "               asking about. If you cannot tell return a ?. Return only the assignment number as integer, do not explain.\n",
    "               Here it is the email:\n",
    "               {email}\n",
    "                \"\"\"\n",
    "\n",
    "email_prompt = PromptTemplate(input_variables=['email'], template=email_context)\n",
    "help_prompt = PromptTemplate(input_variables=['email'], template=help_context)\n",
    "\n",
    "chain_email = email_prompt | llm\n",
    "chain_help = help_prompt | llm\n",
    "\n",
    "for i in range(1,3):\n",
    "    email = get_email(i)\n",
    "    classification = chain_email.invoke(email).content.strip()\n",
    "    if classification == 'help':\n",
    "        assignment = chain_help.invoke(email).content.strip()\n",
    "        print(f\"Email #{i} is a question about assignment #{assignment}\")\n",
    "    else:\n",
    "        print(f\"Email #{i} is: {classification}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43356f6a",
   "metadata": {},
   "source": [
    "### Here he have another application. Finding names within a text, that could be misclassified as typos. iamnotatypo.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "891b4757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the human names extracted from the text, each on a separate line:\n",
      "\n",
      "Esmae  \n",
      "Zarah  \n",
      "priti  \n",
      "María José García Martínez  \n",
      "Rafe  \n",
      "Ayda  \n",
      "Ruaridh  \n",
      "Eesa  \n",
      "Otillie  \n",
      "Matei Smith\n"
     ]
    }
   ],
   "source": [
    "SAMPLE = \"\"\"Esmae and Zarah have been friends since college. After graduation they inverviewed with priti for a job at the technotryne corporation, whose\n",
    "flagship product is named Futuricore, which was developed by a programmer named María José García Martínez. After a successul interview they met with their friends Rafe and Ayda to\n",
    "celebrate good times. Their first day on the job, they met three other employees, Ruaridh, Eesa, and Otillie. Later they were joined by Matei Smith\"\"\"\n",
    "\n",
    "name_context = \"\"\"Find all human names in the following text. Extract complete name, return only names.\\n\n",
    "                  Output each name on a separate line.\\n\n",
    "                  {subject}.\\n\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=name_context,\n",
    "    input_variables=['subject']\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "print(chain.invoke({'subject': SAMPLE}).content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tadsml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
